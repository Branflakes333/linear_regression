{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6581f76e",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Linear Regression Analysis</h1>\n",
    "<h1 style=\"text-align: center;\">Homework 4</h1>\n",
    "<h3 style=\"text-align: center;\">Brandon Miner</h3>\n",
    "<h3 style=\"text-align: center;\">September 25, 2025</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b7502",
   "metadata": {},
   "source": [
    "**Directions**: Submit a .pdf file containing your responses. The .pdf can be converted from a Latex file, pictures of your handwritten solutions, word files, markdown files, etc. If there are coding problems, upload a separate notebook for Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0905feab",
   "metadata": {},
   "source": [
    "### *Written Questions*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa00105a",
   "metadata": {},
   "source": [
    "1. Suppose we have fit a MLR model between response variable $Y$ and predictors $X_1,\\dots,X_{p−1}$. using a data of size $n$. The global F-test aka omnibus test considers the hypotheses:\n",
    "$$\n",
    "H_0 : y_i = \\beta_0 + \\epsilon_i \\text{ vs. } \n",
    "H_1 : y_i = \\beta_0 | \\beta_1X_{1i} + \\dots + \\beta_{p-1}X_{(p-1)i}+\\epsilon_i\n",
    "$$\n",
    "using the statistic $F = \\frac{MSR}{MSE}$ where $MSR$ and $MSE$ are calculated under the full model. Show that this definition is equivalent to the alternative formulation of the F statistic as:\n",
    "\n",
    "$$\n",
    "F_{alt} = \n",
    "\\frac{\n",
    "    \\frac{SSE_{H_0} − SSE_{H_1}}\n",
    "        {df_{SSE_{H_0}} −df_{SSE_{H_1}}}}\n",
    "    {\\frac{SSE_{H_1}}\n",
    "        {df_{SSE_{H_1}}}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d636ef1",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "$$\n",
    "F_{alt} = \n",
    "\\frac{\n",
    "    \\frac{SSE_{H_0} − SSE_{H_1}}\n",
    "        {df_{SSE_{H_0}} −df_{SSE_{H_1}}}}\n",
    "    {\\frac{SSE_{H_1}}\n",
    "        {df_{SSE_{H_1}}}}\n",
    "=\n",
    "\\frac{\n",
    "    \\frac{SSE_{H_0} − SSE_{H_1}}\n",
    "        {n − (n-1)}}\n",
    "    {\\frac{SSE_{H_1}}\n",
    "        {n-2}}\n",
    "=\n",
    "\\frac{\n",
    "    SSE_{H_0} − SSE_{H_1}}\n",
    "    {\\frac{SSE_{H_1}}\n",
    "        {n-2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68dd774",
   "metadata": {},
   "source": [
    "from here realize that\n",
    "$$\n",
    "MSE = \\frac{SSE_{H_1}}{n-2},\\space MSR= SSE_{H_0} - SSE_{H_1}\n",
    "$$\n",
    "Because this is the definition of MSE, and MSR is the remaining error of the reduced model.\n",
    "\n",
    "Thus\n",
    "$$\n",
    "= \\frac{MSR}{MSE}\n",
    "$$\n",
    "As desired"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d3b94",
   "metadata": {},
   "source": [
    "2. If a predictor variable is categorical with six states and we want to include it in a regression model, how many dummy variables do we need to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2d2b8",
   "metadata": {},
   "source": [
    "**ANSWER** \n",
    "\n",
    "You would include 5 dummy variables because having the same number of dummy variables as categories induces perfect multicollinearity. Mathematically, this makes our predictors $X$ invertible, and thus $X^TX$ invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2f932",
   "metadata": {},
   "source": [
    "3. Suppose a predictor variable is categorical with three states “C1”, “C2”, “C3”. When we include it in a regression model and the individual t tests used “C1” as reference level, and showed “C2” is significant and “C3” is not. Would you conclude that “we should drop C3 and fit a new model”? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a28727c",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "I would not immediately drop C3 because it could be possible that C3 is simply correlated with C1 or C2, and the true model could be $Y=\\beta \\text{C3}$. Further exploration is needed to conclude *why* C3 is not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f9b3a5",
   "metadata": {},
   "source": [
    "### *Coding Questions*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab87459",
   "metadata": {},
   "source": [
    "4. This question will help you to understand the calculation of ANOVA in MLR using an example. For\n",
    "the dataset `KelleyBlueBookData.csv`, response= Price against the following predictors: Mileage, Liter, Cylinder (in this order). Treat Cylinder as a quantitative variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98dbb623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th> <td>   0.342</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.340</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   138.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 Sep 2025</td> <th>  Prob (F-statistic):</th> <td>2.18e-72</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:31:55</td>     <th>  Log-Likelihood:    </th> <td> -8367.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   804</td>      <th>  AIC:               </th> <td>1.674e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   800</td>      <th>  BIC:               </th> <td>1.676e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 4707.6150</td> <td> 1602.866</td> <td>    2.937</td> <td> 0.003</td> <td> 1561.296</td> <td> 7853.934</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mileage</th>   <td>   -0.1544</td> <td>    0.035</td> <td>   -4.461</td> <td> 0.000</td> <td>   -0.222</td> <td>   -0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Liter</th>     <td> 1545.2522</td> <td>  893.411</td> <td>    1.730</td> <td> 0.084</td> <td> -208.454</td> <td> 3298.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cylinder</th>  <td> 2847.9345</td> <td>  712.040</td> <td>    4.000</td> <td> 0.000</td> <td> 1450.247</td> <td> 4245.622</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.158</td> <th>  Durbin-Watson:     </th> <td>   0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 444.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.499</td>  <th>  Prob(JB):          </th> <td>2.56e-97</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.071</td>  <th>  Cond. No.          </th> <td>1.37e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.37e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Price       & \\textbf{  R-squared:         } &     0.342   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.340   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     138.8   \\\\\n",
       "\\textbf{Date:}             & Thu, 25 Sep 2025 & \\textbf{  Prob (F-statistic):} &  2.18e-72   \\\\\n",
       "\\textbf{Time:}             &     18:31:55     & \\textbf{  Log-Likelihood:    } &   -8367.7   \\\\\n",
       "\\textbf{No. Observations:} &         804      & \\textbf{  AIC:               } & 1.674e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &         800      & \\textbf{  BIC:               } & 1.676e+04   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &    4707.6150  &     1602.866     &     2.937  &         0.003        &     1561.296    &     7853.934     \\\\\n",
       "\\textbf{Mileage}   &      -0.1544  &        0.035     &    -4.461  &         0.000        &       -0.222    &       -0.086     \\\\\n",
       "\\textbf{Liter}     &    1545.2522  &      893.411     &     1.730  &         0.084        &     -208.454    &     3298.958     \\\\\n",
       "\\textbf{Cylinder}  &    2847.9345  &      712.040     &     4.000  &         0.000        &     1450.247    &     4245.622     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.158 & \\textbf{  Durbin-Watson:     } &    0.074  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  444.825  \\\\\n",
       "\\textbf{Skew:}          &   1.499 & \\textbf{  Prob(JB):          } & 2.56e-97  \\\\\n",
       "\\textbf{Kurtosis:}      &   5.071 & \\textbf{  Cond. No.          } & 1.37e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.37e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.342\n",
       "Model:                            OLS   Adj. R-squared:                  0.340\n",
       "Method:                 Least Squares   F-statistic:                     138.8\n",
       "Date:                Thu, 25 Sep 2025   Prob (F-statistic):           2.18e-72\n",
       "Time:                        18:31:55   Log-Likelihood:                -8367.7\n",
       "No. Observations:                 804   AIC:                         1.674e+04\n",
       "Df Residuals:                     800   BIC:                         1.676e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   4707.6150   1602.866      2.937      0.003    1561.296    7853.934\n",
       "Mileage       -0.1544      0.035     -4.461      0.000      -0.222      -0.086\n",
       "Liter       1545.2522    893.411      1.730      0.084    -208.454    3298.958\n",
       "Cylinder    2847.9345    712.040      4.000      0.000    1450.247    4245.622\n",
       "==============================================================================\n",
       "Omnibus:                      214.158   Durbin-Watson:                   0.074\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              444.825\n",
       "Skew:                           1.499   Prob(JB):                     2.56e-97\n",
       "Kurtosis:                       5.071   Cond. No.                     1.37e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.37e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "kbbd = pd.read_csv(\"../../data/KelleyBlueBookData.csv\")\n",
    "\n",
    "model_4 = ols('Price~Mileage+Liter+Cylinder',data=kbbd).fit()\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6784131",
   "metadata": {},
   "source": [
    "(a) Run the sequential ANOVA for the fitted model. Report null and alternative hypothesis, the F\n",
    "stat, and the p-value for the F-test for dropping or including the ‘Cylinder’ predictor. What is\n",
    "the conclusion of this test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dce4c958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mileage</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.605590e+09</td>\n",
       "      <td>1.605590e+09</td>\n",
       "      <td>24.890171</td>\n",
       "      <td>7.448191e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liter</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.421824e+10</td>\n",
       "      <td>2.421824e+10</td>\n",
       "      <td>375.435819</td>\n",
       "      <td>7.134623e-69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cylinder</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.031948e+09</td>\n",
       "      <td>1.031948e+09</td>\n",
       "      <td>15.997457</td>\n",
       "      <td>6.930502e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>800.0</td>\n",
       "      <td>5.160560e+10</td>\n",
       "      <td>6.450701e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             df        sum_sq       mean_sq           F        PR(>F)\n",
       "Mileage     1.0  1.605590e+09  1.605590e+09   24.890171  7.448191e-07\n",
       "Liter       1.0  2.421824e+10  2.421824e+10  375.435819  7.134623e-69\n",
       "Cylinder    1.0  1.031948e+09  1.031948e+09   15.997457  6.930502e-05\n",
       "Residual  800.0  5.160560e+10  6.450701e+07         NaN           NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_anova = sm.stats.anova_lm(model_4,typ=1)\n",
    "model_anova"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b50462",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "The Null Hypothesis is that Cylinder is not a significant predictor of price. \n",
    "\n",
    "The Alternative Hypothesis is that Cylinder is a significant predictor of price.\n",
    "\n",
    "The F-stat is 15.997457.\n",
    "\n",
    "The p-value is 6.930502e-05\n",
    "\n",
    "Putting this all together, we can reject the null hypothesis at a 5% significance level. Cylinder appears to be a significant predictor of price. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d4e8c9",
   "metadata": {},
   "source": [
    "(b) Manually run the test in part (a) yourself: 1. fit the null model in python and extract $SSE$ and\n",
    "degrees of freedom of this $SSE$; then 2. fit the alternative model in python and extract $SSE$ and\n",
    "degrees of freedom of this $SSE$. Plug in the numbers to\n",
    "\n",
    "$$\n",
    "F_{alt} = \n",
    "\\frac{\n",
    "    \\frac{SSE_{H_0} − SSE_{H_1}}\n",
    "        {df_{SSE_{H_0}} −df_{SSE_{H_1}}}}\n",
    "    {\\frac{SSE_{H_1}}\n",
    "        {df_{SSE_{H_1}}}}\n",
    "$$\n",
    "\n",
    "Does the value you calculated match the F-statistic from part (a)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63ea1f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-stat: 15.99745707625833\n",
      "F-alt-stat: 15.99745707625828\n",
      "\n",
      "Difference: 4.973799150320701e-14\n"
     ]
    }
   ],
   "source": [
    "F_stat = model_anova.loc[\"Cylinder\",\"F\"]\n",
    "\n",
    "null_model = ols('Price~Mileage+Liter',data=kbbd).fit()\n",
    "null_anova = sm.stats.anova_lm(null_model)\n",
    "\n",
    "SSEH0 = null_anova.loc['Residual','sum_sq']\n",
    "dfSSEH0 = null_anova.loc['Residual','df']\n",
    "\n",
    "SSEH1 = model_anova.loc['Residual','sum_sq']\n",
    "dfSSEH1 = model_anova.loc['Residual','df']\n",
    "\n",
    "Falt = ((SSEH0 - SSEH1) / (dfSSEH0 - dfSSEH1)) / (SSEH1/dfSSEH1)\n",
    "\n",
    "print(f\"F-stat: {F_stat}\\nF-alt-stat: {Falt}\\n\\nDifference: {F_stat - Falt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cbb7fb",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "We know from Q1 that the F stat and F-alt stat should be the same. Here we can see that they are effectively the same, only off due to minor rounding error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa82ff",
   "metadata": {},
   "source": [
    "(c) Run the partial ANOVA (typ=2) for the fitted model. Does the F-test for ’Cylinder’ match the\n",
    "F-test from part (a)? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d9bc1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq F-stat: 15.99745707625833\n",
      "Min-One F-stat: 15.997457076258485\n",
      " \n",
      "Difference: -1.545430450278218e-13\n"
     ]
    }
   ],
   "source": [
    "model_anova_2 = sm.stats.anova_lm(model_4,typ=2)\n",
    "F_stat_2 = model_anova_2.loc[\"Cylinder\",\"F\"]\n",
    "\n",
    "print(f\"seq F-stat: {F_stat}\\nMin-One F-stat: {F_stat_2}\")\n",
    "\n",
    "print(f\" \\nDifference: {F_stat - F_stat_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d065ac15",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "The F-tests are very similar. This makes sense if we assume that the number of cylinders are not correlated with the other predictors and a strong predictor of price. This would result in both tests passing strongly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471a8a5",
   "metadata": {},
   "source": [
    "(d) From the partial ANOVA (typ=2) table in (c), report the null and alternative hypothesis, the F\n",
    "stat, and the p-value for the F-test for dropping or including the ‘Mileage’ predictor. Interpret\n",
    "the result of this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "404fa072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.930501986611917e-05)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_anova_2.loc['Cylinder','PR(>F)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4ac176",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "The Null Hypothesis is that Cylinder is not a significant predictor of price. \n",
    "\n",
    "The Alternative Hypothesis is that Cylinder is a significant predictor of price.\n",
    "\n",
    "The F-stat is 15.997457076258485\n",
    "\n",
    "The p-value is 6.930501986611917e-05\n",
    "\n",
    "Putting this all together, we can reject the null hypothesis at a 5% significance level. Cylinder appears to be a significant predictor of price. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7305bc9f",
   "metadata": {},
   "source": [
    "(e) Manually run the test in part (d) yourself: 1. fit the null model in python and extract SSE and\n",
    "degrees of freedom of this SSE; then 2. fit the alternative model in python and extract SSE and\n",
    "degrees of freedom of this SSE. Plug in the numbers to\n",
    "\n",
    "$$\n",
    "F_{alt} = \n",
    "\\frac{\n",
    "    \\frac{SSE_{H_0} − SSE_{H_1}}\n",
    "        {df_{SSE_{H_0}} −df_{SSE_{H_1}}}}\n",
    "    {\\frac{SSE_{H_1}}\n",
    "        {df_{SSE_{H_1}}}}\n",
    "$$\n",
    "\n",
    "Does the value you calculated match the F-statistic from part (d)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79e547c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-stat: 15.997457076258485\n",
      "F-alt-stat: 15.99745707625828\n",
      "\n",
      "Difference: 2.042810365310288e-13\n"
     ]
    }
   ],
   "source": [
    "F_stat_2 = model_anova_2.loc[\"Cylinder\",\"F\"]\n",
    "\n",
    "null_model = ols('Price~Mileage+Liter',data=kbbd).fit()\n",
    "null_anova = sm.stats.anova_lm(null_model, typ=2)\n",
    "\n",
    "SSEH0 = null_anova.loc['Residual','sum_sq']\n",
    "dfSSEH0 = null_anova.loc['Residual','df']\n",
    "\n",
    "SSEH1 = model_anova.loc['Residual','sum_sq']\n",
    "dfSSEH1 = model_anova.loc['Residual','df']\n",
    "\n",
    "Falt = ((SSEH0 - SSEH1) / (dfSSEH0 - dfSSEH1)) / (SSEH1/dfSSEH1)\n",
    "\n",
    "print(f\"F-stat: {F_stat}\\nF-alt-stat: {Falt}\\n\\nDifference: {F_stat - Falt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb7289",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "They are similar which makes sense mathematically as talked about prior as well as logically since the different F_stats for typ1 and typ2 are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e7ff73",
   "metadata": {},
   "source": [
    "5. This question will help you to understand the calculation of $R^2$ and $R^2_{adj}$ in MLR using an example. For the dataset `KelleyBlueBookData.csv`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe262b66",
   "metadata": {},
   "source": [
    "(a) Fit Model 1: a model which considers Price as the response and regresses it against the predictors Mileage and Cylinder. Report the $R^2$ and $R^2_{adj}$ values from the summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "370ba4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th> <td>   0.340</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.338</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   206.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 Sep 2025</td> <th>  Prob (F-statistic):</th> <td>5.95e-73</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:04:49</td>     <th>  Log-Likelihood:    </th> <td> -8369.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   804</td>      <th>  AIC:               </th> <td>1.674e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   801</td>      <th>  BIC:               </th> <td>1.676e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 3145.7503</td> <td> 1325.934</td> <td>    2.372</td> <td> 0.018</td> <td>  543.034</td> <td> 5748.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mileage</th>   <td>   -0.1524</td> <td>    0.035</td> <td>   -4.401</td> <td> 0.000</td> <td>   -0.220</td> <td>   -0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cylinder</th>  <td> 4027.6746</td> <td>  204.612</td> <td>   19.684</td> <td> 0.000</td> <td> 3626.036</td> <td> 4429.313</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>198.944</td> <th>  Durbin-Watson:     </th> <td>   0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 385.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.439</td>  <th>  Prob(JB):          </th> <td>1.96e-84</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.797</td>  <th>  Cond. No.          </th> <td>1.01e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.01e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Price       & \\textbf{  R-squared:         } &     0.340   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.338   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     206.2   \\\\\n",
       "\\textbf{Date:}             & Thu, 25 Sep 2025 & \\textbf{  Prob (F-statistic):} &  5.95e-73   \\\\\n",
       "\\textbf{Time:}             &     19:04:49     & \\textbf{  Log-Likelihood:    } &   -8369.2   \\\\\n",
       "\\textbf{No. Observations:} &         804      & \\textbf{  AIC:               } & 1.674e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &         801      & \\textbf{  BIC:               } & 1.676e+04   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &    3145.7503  &     1325.934     &     2.372  &         0.018        &      543.034    &     5748.467     \\\\\n",
       "\\textbf{Mileage}   &      -0.1524  &        0.035     &    -4.401  &         0.000        &       -0.220    &       -0.084     \\\\\n",
       "\\textbf{Cylinder}  &    4027.6746  &      204.612     &    19.684  &         0.000        &     3626.036    &     4429.313     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 198.944 & \\textbf{  Durbin-Watson:     } &    0.077  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  385.493  \\\\\n",
       "\\textbf{Skew:}          &   1.439 & \\textbf{  Prob(JB):          } & 1.96e-84  \\\\\n",
       "\\textbf{Kurtosis:}      &   4.797 & \\textbf{  Cond. No.          } & 1.01e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.01e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.340\n",
       "Model:                            OLS   Adj. R-squared:                  0.338\n",
       "Method:                 Least Squares   F-statistic:                     206.2\n",
       "Date:                Thu, 25 Sep 2025   Prob (F-statistic):           5.95e-73\n",
       "Time:                        19:04:49   Log-Likelihood:                -8369.2\n",
       "No. Observations:                 804   AIC:                         1.674e+04\n",
       "Df Residuals:                     801   BIC:                         1.676e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   3145.7503   1325.934      2.372      0.018     543.034    5748.467\n",
       "Mileage       -0.1524      0.035     -4.401      0.000      -0.220      -0.084\n",
       "Cylinder    4027.6746    204.612     19.684      0.000    3626.036    4429.313\n",
       "==============================================================================\n",
       "Omnibus:                      198.944   Durbin-Watson:                   0.077\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              385.493\n",
       "Skew:                           1.439   Prob(JB):                     1.96e-84\n",
       "Kurtosis:                       4.797   Cond. No.                     1.01e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.01e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5a = ols(\"Price~Mileage+Cylinder\",data=kbbd).fit()\n",
    "model_5a.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9510395a",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "R-squared:\t0.340\n",
    "\n",
    "Adj. R-squared:\t0.338"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f5d530",
   "metadata": {},
   "source": [
    "Calculate $R^2$ and $R^2_{adj}$ for the model in part (a) yourself. Obtain the SSE and SST of the model in part (a), then plug in the formulas: \n",
    "$R^2 = 1 − \\frac{SSE}{SST}$ and \n",
    "$R^2_{adj} = 1 - \\frac{SSE/n −p}{SST/n −1}$.\n",
    "Do the values match with the python output in (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2318a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared : 0.33982070826263056\n",
      "R-adj-Squared : 0.3381743690825033\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "SSE = np.sum((kbbd['Price'] - model_5a.fittedvalues) ** 2)\n",
    "SST = np.sum((kbbd['Price'] - np.mean(kbbd['Price'])) ** 2)\n",
    "n = len(kbbd)\n",
    "R_squared = 1 - SSE/SST\n",
    "R_adj_squared = 1 - (SSE / (n-2)) / (SST / n-1)\n",
    "\n",
    "print(f\"R-Squared : {R_squared}\\nR-adj-Squared : {R_adj_squared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18792b68",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "Asside from some rounding error, the values are effectively the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210c277",
   "metadata": {},
   "source": [
    "(c) Fit Model 2: a model which considers Price as the response and regresses it against the predictors Mileage, Liter and Cylinder. Report the $R^2$ and $R^2_{adj}$ values from the summary table. Which\n",
    "model is preferable according to R2adj between Model 1 and Model 2? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "968e292a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th> <td>   0.342</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.340</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   138.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 Sep 2025</td> <th>  Prob (F-statistic):</th> <td>2.18e-72</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:20:07</td>     <th>  Log-Likelihood:    </th> <td> -8367.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   804</td>      <th>  AIC:               </th> <td>1.674e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   800</td>      <th>  BIC:               </th> <td>1.676e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 4707.6150</td> <td> 1602.866</td> <td>    2.937</td> <td> 0.003</td> <td> 1561.296</td> <td> 7853.934</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mileage</th>   <td>   -0.1544</td> <td>    0.035</td> <td>   -4.461</td> <td> 0.000</td> <td>   -0.222</td> <td>   -0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Liter</th>     <td> 1545.2522</td> <td>  893.411</td> <td>    1.730</td> <td> 0.084</td> <td> -208.454</td> <td> 3298.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cylinder</th>  <td> 2847.9345</td> <td>  712.040</td> <td>    4.000</td> <td> 0.000</td> <td> 1450.247</td> <td> 4245.622</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.158</td> <th>  Durbin-Watson:     </th> <td>   0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 444.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.499</td>  <th>  Prob(JB):          </th> <td>2.56e-97</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.071</td>  <th>  Cond. No.          </th> <td>1.37e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.37e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Price       & \\textbf{  R-squared:         } &     0.342   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.340   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     138.8   \\\\\n",
       "\\textbf{Date:}             & Thu, 25 Sep 2025 & \\textbf{  Prob (F-statistic):} &  2.18e-72   \\\\\n",
       "\\textbf{Time:}             &     19:20:07     & \\textbf{  Log-Likelihood:    } &   -8367.7   \\\\\n",
       "\\textbf{No. Observations:} &         804      & \\textbf{  AIC:               } & 1.674e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &         800      & \\textbf{  BIC:               } & 1.676e+04   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &    4707.6150  &     1602.866     &     2.937  &         0.003        &     1561.296    &     7853.934     \\\\\n",
       "\\textbf{Mileage}   &      -0.1544  &        0.035     &    -4.461  &         0.000        &       -0.222    &       -0.086     \\\\\n",
       "\\textbf{Liter}     &    1545.2522  &      893.411     &     1.730  &         0.084        &     -208.454    &     3298.958     \\\\\n",
       "\\textbf{Cylinder}  &    2847.9345  &      712.040     &     4.000  &         0.000        &     1450.247    &     4245.622     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.158 & \\textbf{  Durbin-Watson:     } &    0.074  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  444.825  \\\\\n",
       "\\textbf{Skew:}          &   1.499 & \\textbf{  Prob(JB):          } & 2.56e-97  \\\\\n",
       "\\textbf{Kurtosis:}      &   5.071 & \\textbf{  Cond. No.          } & 1.37e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.37e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.342\n",
       "Model:                            OLS   Adj. R-squared:                  0.340\n",
       "Method:                 Least Squares   F-statistic:                     138.8\n",
       "Date:                Thu, 25 Sep 2025   Prob (F-statistic):           2.18e-72\n",
       "Time:                        19:20:07   Log-Likelihood:                -8367.7\n",
       "No. Observations:                 804   AIC:                         1.674e+04\n",
       "Df Residuals:                     800   BIC:                         1.676e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   4707.6150   1602.866      2.937      0.003    1561.296    7853.934\n",
       "Mileage       -0.1544      0.035     -4.461      0.000      -0.222      -0.086\n",
       "Liter       1545.2522    893.411      1.730      0.084    -208.454    3298.958\n",
       "Cylinder    2847.9345    712.040      4.000      0.000    1450.247    4245.622\n",
       "==============================================================================\n",
       "Omnibus:                      214.158   Durbin-Watson:                   0.074\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              444.825\n",
       "Skew:                           1.499   Prob(JB):                     2.56e-97\n",
       "Kurtosis:                       5.071   Cond. No.                     1.37e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.37e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5a = ols(\"Price~Mileage+Liter+Cylinder\",data=kbbd).fit()\n",
    "model_5a.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d503a630",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "R-squared:\t0.342\n",
    "\n",
    "Adj. R-squared:\t0.340\n",
    "\n",
    "According to Adj. R-squared, I'd prefer model 1 because it has a larger Adj. R-squared. But it is important to note how small both Adj. R-squared values they are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06eca4c",
   "metadata": {},
   "source": [
    "Open question: Consider simultaneously the t-test results, ANOVA, $R^2_{adj}$ and any other concepts\n",
    "we have covered so far (e.g. diagnostics). Which model would you choose, Model 1 or Model 2?\n",
    "Argue for your model in terms of these statistics and also the real life meaning of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa1002d",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "I would use Model 2 because, while its Adj. R-squared is lower, it's not that much lower and liter seems to be a the best predictor of price out of iter, mileage, and cylinder based on its incredibly small p-value from the sequential ANOVA. This leads me to believe the true model contains liter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linear_regression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
